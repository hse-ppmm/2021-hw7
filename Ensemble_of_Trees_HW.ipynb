{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Ensemble_of_Trees_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GqgljrZLAkP"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R4Ebn5eLAkj"
      },
      "source": [
        "Случайный лес\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSKhLrD-LAkj"
      },
      "source": [
        "np.random.seed(43)\n",
        "\n",
        "n = 250\n",
        "\n",
        "mu1 = np.array([0.0,0])\n",
        "mu2 = np.array([1.0,0])\n",
        "sigma1 = 5.0 * np.diag(np.array([1.0, 1.0]))\n",
        "sigma2 = 0.5 * np.diag(np.array([1.0, 1.0]))\n",
        "\n",
        "x1 = np.random.multivariate_normal(mu1, sigma1, n)\n",
        "x2 = np.random.multivariate_normal(mu2, sigma2, n)\n",
        "x = np.vstack([x1, x2])\n",
        "y = np.concatenate([np.full(x1.shape[0], 0), np.full(x2.shape[0], 1)])\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(*x1.T,s=2.5)\n",
        "plt.scatter(*x2.T,s=2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqfEaKG-LAkj"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MywloIJDLAkj"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "c = RandomForestClassifier(random_state=0, max_depth=15)\n",
        "\n",
        "c.fit(x_train, y_train)\n",
        "pred = c.predict(xx_test).reshape(xx.shape)\n",
        "\n",
        "x1_train = x_train[y_train == 0]\n",
        "x2_train = x_train[y_train == 1]\n",
        "\n",
        "plt.figure()\n",
        "plt.xlim(-2,3)\n",
        "plt.ylim(-2,3)\n",
        "plt.contourf(xx, yy, pred, cmap=\"pink_r\")\n",
        "plt.scatter(*x1_train.T,s=2.5)\n",
        "plt.scatter(*x2_train.T,s=2.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LoAuppaLAkk"
      },
      "source": [
        "**Задание 7.1** Используйте готовый класс `RandomForestClassifier` чтобы проверить как работает классификация с помощью метода случайного леса. С помощью метода кросс-валидации получите и постройте на графике зависимость точности (accuracy) (для учебного и тестового множеств) от максимальной глубины деревьев случайного леса. Используйте данные из примера про дерево классификации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg2ssXnWLAkk"
      },
      "source": [
        "# код потерялся"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfwDIowgLAkk"
      },
      "source": [
        "scores = flat_dict(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLER3NNKLAkl"
      },
      "source": [
        "plt.plot(max_depths, scores['train_accuracy'].mean(axis=1), '-*', label=\"train accuracy\")\n",
        "plt.plot(max_depths, scores['test_accuracy'].mean(axis=1), '-*', label=\"test accuracy\")\n",
        "plt.xlabel(\"Tree max depth\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "_ = plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6QVJQAqLAkl"
      },
      "source": [
        "import sklearn.metrics\n",
        "\n",
        "def evaluate(c, x, y):\n",
        "    y_pred = c.predict(x)\n",
        "    if getattr(c, \"decision_function\", None):\n",
        "        scores = c.decision_function(x)\n",
        "    else:\n",
        "        scores = c.predict_proba(x)[:,1]\n",
        "\n",
        "    tn, fp, fn, tp = sklearn.metrics.confusion_matrix(y, y_pred, labels=['h', 'g']).ravel()\n",
        "    accuracy  = (tp + tn) / (tn + fp + fn + tp)\n",
        "    precision = tp / (tp + fp)\n",
        "    recall    = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    baccuracy = 0.5 * (specificity + recall)\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "    \n",
        "    print(\"Accuracy                  = {:.4f}\".format(accuracy))\n",
        "    print(\"Ballanced accuracy        = {:.4f}\".format(baccuracy))\n",
        "    print(\"F1                        = {:.4f}\".format(f1))\n",
        "    print(\"Precision (PPV)           = {:.4f}\".format(precision))\n",
        "    print(\"Recall (sensitivity, TPR) = {:.4f}\".format(recall))\n",
        "    print(\"Specificity (TNR, 1-FPR)  = {:.4f}\".format(specificity))\n",
        "    \n",
        "    min_score, max_score = np.min(scores), np.max(scores)\n",
        "    bins = np.linspace(min_score, max_score, 25)\n",
        "    plt.figure()\n",
        "    plt.hist(scores[y.reshape(-1) == 'h'], bins, alpha=0.5, label='Hadron (negative)')\n",
        "    plt.hist(scores[y.reshape(-1) == 'g'], bins, alpha=0.5, label='Gamma (positive)')\n",
        "    plt.xlabel(\"Decision function (value)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.legend()\n",
        "    \n",
        "    tpr, fpr, _ = sklearn.metrics.roc_curve(y, scores, pos_label='g')\n",
        "    auc = sklearn.metrics.roc_auc_score(y, scores)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.title(\"Receiver operating characteristic\")\n",
        "    plt.xlabel(\"False positive rate\")\n",
        "    plt.ylabel(\"True positive rate\")\n",
        "    print(\"AUC                       = {:.4f}\".format(auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-peCeKLAkl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "names = [\"length\", \"width\", \"size\", \"conc\", \"conc1\", \"asym\", \"m3long\", \"m3trans\", \"alpha\", \"dist\", \"class\"]\n",
        "data = pd.read_csv('magic04.csv', names=names)\n",
        "\n",
        "x = np.asarray(data.iloc[:, :-1])\n",
        "y = np.asarray(data.iloc[:, [-1]])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hs_NoqfyLAkm"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "c = RandomForestClassifier(random_state=0)\n",
        "\n",
        "c.fit(x_train, y_train.reshape(-1))\n",
        "\n",
        "train_acc = c.score(x_train, y_train) # accuracy\n",
        "test_acc = c.score(x_test, y_test)\n",
        "\n",
        "evaluate(c, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzMoVYuALAkm"
      },
      "source": [
        "**Задание 7.2**\n",
        "\n",
        "Используя данные с черенковского телескопа из файла `magic04.csv` и метод кросс-валидации подберите максимальную глубину случайного леса таким образом, чтобы получить наилучший AUC при бинарной классификации методом случайного леса (`RandomForestClassifier`).\n",
        "Постройте график зависимости AUC от глубины дерева."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW2vws-MLAkm"
      },
      "source": [
        "# код потерялся"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5EZq21eLAkm"
      },
      "source": [
        "scores = flat_dict(scores)\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "print(\"fit time = {}\".format(scores['fit_time'].mean(axis=1)))\n",
        "for s in scoring.keys():\n",
        "    print(\"{} = {}\".format(s, scores[\"test_{}\".format(s)].mean(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yFpq4mDLAkn"
      },
      "source": [
        "plt.plot(max_depths, scores['test_auc'].mean(axis=1),'-*')\n",
        "plt.xlabel(\"Tree depth\")\n",
        "plt.ylabel(\"ROC AUC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtfuQy4VLAkn"
      },
      "source": [
        "Адаптивный бустинг\n",
        "----------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7FGQbU8LAkn"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "c = AdaBoostClassifier(random_state=0, n_estimators=200)\n",
        "\n",
        "c.fit(x_train, y_train)\n",
        "\n",
        "train_acc = c.score(x_train, y_train) # accuracy\n",
        "test_acc = c.score(x_test, y_test)\n",
        "\n",
        "evaluate(c, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4VQbNs4LAkn"
      },
      "source": [
        "**Задание 7.3**\n",
        "\n",
        "Используя данные с черенковского телескопа из файла `magic04.csv` и метод кросс-валидации подберите максимальную глубину дерева классификации, чтобы получить наилучший AUC при бинарной классификации методом адаптивного бустинга (`AdaBoostClassifier`).\n",
        "Постройте график зависимости AUC от глубины дерева."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIVWuL_LLAkn"
      },
      "source": [
        "# код потерялся"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRiBn7dELAkn"
      },
      "source": [
        "scores = flat_dict(scores)\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "print(\"fit time = {}\".format(scores['fit_time'].mean(axis=1)))\n",
        "for s in scoring.keys():\n",
        "    print(\"{} = {}\".format(s, scores[\"test_{}\".format(s)].mean(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twXIlxhLLAkn"
      },
      "source": [
        "plt.plot(max_depths, scores['test_auc'].mean(axis=1),'-*')\n",
        "plt.xlabel(\"Tree depth\")\n",
        "plt.ylabel(\"ROC AUC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeEQmCjmLAkn"
      },
      "source": [
        "Градиентный бустинг\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEMDp99TLAko"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "c = GradientBoostingClassifier(random_state=0, n_estimators=200)\n",
        "\n",
        "c.fit(x_train, y_train)\n",
        "\n",
        "train_acc = c.score(x_train, y_train) # accuracy\n",
        "test_acc = c.score(x_test, y_test)\n",
        "\n",
        "evaluate(c, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxOX2uKtLAko"
      },
      "source": [
        "**Задание 7.4**\n",
        "\n",
        "Используя данные с черенковского телескопа из файла `magic04.csv` и метод кросс-валидации подберите максимальную глубину дерева классификации, чтобы получить наилучший AUC при бинарной классификации методом градиентного бустинга (`GradientBoostingClassifier`).\n",
        "Постройте график зависимости AUC от глубины дерева."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEp02M_TLAkp"
      },
      "source": [
        "# код потерялся"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W4mZ_55LAkq"
      },
      "source": [
        "scores = flat_dict(scores)\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "print(\"fit time = {}\".format(scores['fit_time'].mean(axis=1)))\n",
        "for s in scoring.keys():\n",
        "    print(\"{} = {}\".format(s, scores[\"test_{}\".format(s)].mean(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spfb-JSELAkq"
      },
      "source": [
        "plt.plot(max_depths, scores['test_auc'].mean(axis=1),'-*')\n",
        "plt.xlabel(\"Tree depth\")\n",
        "plt.ylabel(\"ROC AUC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82jXKVYKLAkq"
      },
      "source": [
        "**Задание 7.5**\n",
        "\n",
        "Настройте гиперпараметры для LightGBM. Получите по крайней мере 0.9 по метрике $R^2$ на наборе данных *California Housing* со следующими признаками:\n",
        "* `MedInc` - median income in block\n",
        "* `HouseAge` - median house age in block\n",
        "* `AveRooms` - average number of rooms\n",
        "* `AveBedrms` - average number of bedrooms\n",
        "* `Population` - block population\n",
        "* `AveOccup` - average house occupancy\n",
        "* `Latitude` - house block latitude\n",
        "* `Longitude` - house block longitude\n",
        "\n",
        "Целевая переменная: цена на жильё.\n",
        "\n",
        "[Идеи почерпните в документации к библиотеке](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html)\n",
        "\n",
        "**Первый шаг:** создайте валидационный набор и попробуйте установить `early_stopping_round`, [инструкции см. здесь](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html#early-stopping). \n",
        "\n",
        "**Второй шаг:** определите, есть ли у вас проблемы с переобучением (посмотрите соответствующие графики), попробуйте некоторые [методы регуляризации](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regularization.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BOtPt3TPT4q"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "cal_housing = fetch_california_housing()\n",
        "X_train, X_test, y_train, y_test = train_test_split(cal_housing.data,\n",
        "                                                    cal_housing.target,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtZvZacaLdMs"
      },
      "source": [
        "## Добавьте Ваш код здесь\n",
        "\n",
        "# validation_data = lgb.Dataset() # Create validation set here\n",
        "# train_data = lgb.Dataset()\n",
        "\n",
        "# params = {\n",
        "#     'n_jobs': -1,\n",
        "#     'learning_rate': 0.2,\n",
        "#     #'early_stopping_round': None, # Set to some value\n",
        "# }\n",
        "\n",
        "# num_round = 1000\n",
        "# model = lgb.train(params, train_data,  num_round, valid_sets=[validation_data])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbMrUdDlLdQu"
      },
      "source": [
        "# predictions = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOW2NbzwL6sz"
      },
      "source": [
        "# print(f'Test R^2 score: {r2_score(predictions, y_test):.4f}')\n",
        "# print(f'Test RMSE: {rmse(predictions, y_test):.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa6I2NKyLAkq"
      },
      "source": [
        "Изолирующий лес\n",
        "-----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQzTOEjmLAkr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "wl = np.asarray([7.8636, 8.0485, 8.2286, 8.4043, 8.5758, 8.7436, 8.9078, 9.0686, 9.2262, 9.3809, 9.5328, 9.6820, 9.8286, 9.9728, 10.1148, 10.2545, 10.3922, 10.5279, 10.6616, 10.7935, 10.9237, 11.0521, 11.1790, 11.3042, 11.4280, 11.5503, 11.6711, 11.7907, 11.9089, 12.0258, 12.1415, 12.2560, 12.3693, 12.4816, 12.5927, 12.7028, 12.8118, 12.9199, 13.0269, 13.1330, 13.2382, 13.3425, 13.4459, 13.5485, 10.9929, 11.3704, 11.7357, 12.0899, 12.4339, 12.7687, 13.0948, 13.4131, 13.7239, 14.0278, 14.3252, 14.6166, 14.9022, 15.1825, 15.4576, 15.7280, 15.9937, 16.2551, 16.5123, 16.7656, 17.0151, 17.2610, 17.5034, 17.7425, 17.9784, 18.2113, 18.4412, 18.6682, 18.8925, 19.1142, 19.3334, 19.5500, 19.7643, 19.9763, 20.1861, 20.3937, 20.5992, 20.8026, 21.0041, 21.2037, 21.4014, 21.5973, 21.7914, 21.9838, 22.1745, 22.3636, 22.5511, 22.7371, 22.9216])\n",
        "data = pd.read_csv('lrs.csv', header=None)\n",
        "\n",
        "x = np.asarray(data.iloc[:, 11:54])\n",
        "wl = wl[:x.shape[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcsE5s5ULAks"
      },
      "source": [
        "plt.plot(wl, x[0,:], \"-\")\n",
        "plt.title(\"IRAS/LRS spectra\")\n",
        "plt.ylabel(\"Intensity (units)\")\n",
        "plt.xlabel(\"Wavelength (um)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW5hE7LFLAks"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "z = pca.fit_transform(x)\n",
        "\n",
        "c = IsolationForest(n_estimators=1000, contamination=\"auto\")\n",
        "c.fit(z)\n",
        "\n",
        "pred = c.predict(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4vnuckLAks"
      },
      "source": [
        "_ = plt.scatter(*z.T, s=2.5, c=pred, cmap=\"coolwarm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HOlGGYiLAks"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(wl, pca.components_[0,:], \"-\")\n",
        "plt.plot(wl, pca.components_[1,:], \"-\")\n",
        "plt.title(\"IRAS/LRS spectra\")\n",
        "plt.ylabel(\"Intensity (units)\")\n",
        "_ = plt.xlabel(\"Wavelength (um)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfGKBhDILAku"
      },
      "source": [
        "**Задание 7.6**\n",
        "\n",
        "Используйте данные спектров космических объектов с ИК спутника из файла `lrs.csv` и метод изолирующего леса `IsolationForest`, чтобы найти 10 наболее отличных от остальных спектров. Распечатайте соответсвтвующие таким спектрам строки из исходного объекта `data`. Нарисуйте на графике самый необычный спектр."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lb3MJTD-LAku"
      },
      "source": [
        "# код потерялся"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}